# Infer√™ncia

## Llaudet, E. and Imai, K. (2022). _Data analysis for social science: A friendly and practical introduction_. Princeton University Press. Chapter 3: Inferring Population Characteristics via Survey Research.

> In survey research, we collect data from a subset of observations in order to understand the target population as a whole. The subset of individuals chosen for study is called a `sample`. The number of observations in the sample is represented by $n$, and the number of observations in the target population is represented by $N$. (p. 52)

> A `representative sample` accurately reflects the characteristics of the population from which it is drawn. Characteristics appear in the sample at similar rates as in the population as whole. (p. 52)

> [...] the random selection of individuals from the population makes the sample and the target population identical to each other, on average, in both observed and unobserved traits. (p. 53)

> [On potential challenges] First, to implement random sampling, we need the complete list of observations in the target population. This list is known as the sampling frame. In practice, the sampling frame of a population can be difficult to obtain. Lists of residential addresses, emails, or phone numbers often do not include the entire population of interest. More problematically, the individuals missing tend to be systematically different from those included. (p. 54)

> Before continuing with the analysis, it is worth noting that removing observations with missing values from a dataset might make the remaining sample of observations unrepresentative of the target population, thereby rendering our inferences about the population characteristics invalid. Here, for example, if respondents who refused to prove their level of education were all in favor of Brexit, our analysis of the new dataframe, `bes1`, would undermine the level of support for Brexit. (p. 62)

On `prop.tables`, we can use the `margin` argument to make set the reference group (that is, if the values will add up to 1 at the column level or the row level): `prop.table(table(dataset$var1, dataset$var2), margin = 1)`.

> Another option [other than histograms and tables] for measuring the differences between Brexit supporters and non-supporters in terms of age distribution is to compute and compare `descriptive statistics`. Descriptive statistics numerically summarize the main traits of the distribution of a variable.
>
> We can use two different types of descriptive statistics:
> 
> - Measures of centrality, such as the mean and the median, summarize the center of the distribution.
> - Measures of spread, such as the standard deviation and the variance, summarize the amount of variation of the distribution relative to its center. (p. 71-72)

The mathematical formulation of the standard deviation:

$$
\text{sd}(X) = \sqrt{ \frac{ \sum_{i=1}^{n} (X_i - \bar{X})^2 }{n} }
$$

> Roughly speaking, the standard deviation of a variable provides the average distance between the observations and the mean (in the same unit of measurement as the variable). (p. 73)

> As we will see in detail later in the book, one of the distinct characteristics of normal distributions is that about 95% of the observations fall within two standard deviations from the mean [...]. (p. 75)

üí°When plotting scatterplots, a nice way to analyze the data is to divide the plot in 4 quadrants, according to the mean (or maybe the median) of each variable. As a result, each quadrant will have an objective interpretation (above both means, below both means and so on).

> The correlation coefficient ranges from -1 to 1, and it captures the following two characteristcs of the relationship between two variables:
> 
> - the direction of their linear association, that is, the sign of the slope of the line of best fit (which is the line that best summarizes the data)
> 
> - the strength of their association, that is, the degree to which the two variables are linearly associated with each other (p. 82)

> The correlation is positive whenever the two variables move in the same direction relative to their respective means, that is, when high values in one variable are likely to be associated with high values in the other, and low values in one variable are likely to be associated with low values in the other. (p. 82)

Understanding the correlation formula: first, the z-score, which is the **number of standard deviations the observation is above or below the mean**:

$$
Z_i^X = \dfrac{X_i - \bar{X}}{\text{sd}(X)}
$$

Computing the correlation requires us to convert the observations of both variables to z-scores. Then, the correlation coefficient is calculated as the average of the products of the z-scores of $X$ and $Y$:

$$
\begin{align}
\text{cor}(X, Y) &= \dfrac{\sum^n_{i = 1} Z^X_i \times Z_i^Y}{n} \\
&= \dfrac{Z^X_1 \times Z^Y_1 + Z^X_2 \times Z^Y_2 + \cdots + Z^X_n \times Z^Y_n}{n}
\end{align}
$$

> As a result, the sign of the correlation coefficient will be:
>
> - positive when the two variables tend to move in the same direction relative to their respective means, that is, when above-average values in one variable are usually associated with above-average in the other [...], and when below-average values in one variable are usually associated with below-average values in the other. (p. 86)

> [...] **if two variables have a correlation coefficient of zero, it does not necessarily mean that there is no relationship between them. Is just means that there is no linear relationship between them.** For example, the two variables depicted in the figure in the margin have a strong parabolic relationship. Their correlation is approximately zero, however, because there is no line that would summarize the relationship well. (p. 88)


## Kellstedt, P. M.,; Whitten, G. D. (2018). The fundamentals of political science research. Cambridge University Press., Cap. 6: Probabilidade e infer√™ncia estat√≠stica.

> Um **evento** √© o resultado de uma observa√ß√£o aleat√≥ria. Dois ou mais eventos podem ser chamados de **eventos independentes** se a realiza√ß√£o de um dos eventos n√£o afeta a realiza√ß√£o dos demais. Por exemplo, o lan√ßamento de dois dados representa eventos independentes, porque o lan√ßamento do primeiro dado n√£o afeta o resultado do lan√ßamento do segundo.
>
> A probabilidade possui algumas propriedades fundamentais. Primeiro, todos os eventos possuem alguma probabilidade de ocorrer e essa chance varia de 0 a 1. Uma probabilidade de valor 0 significa que o evento √© imposs√≠vel, e uma probabilidade com valor igual a 1 significa que o evento acontecer√° com absoluta certeza. Por exemplo, se lan√ßarmos dois dados honestos e somarmos as faces voltadas para cima, a probabilidade da soma das faces ser igual a 13 √© 0, uma vez que o valor mais alto poss√≠vel √© 12.
> 
> Segundo, a soma de todos os eventos poss√≠veis deve ser exatamente 1. Ou seja, sempre que fazemos uma observa√ß√£o aleat√≥ria de um conjunto de eventos poss√≠veis, devemos observar um desses eventos. Por exemplo, se voc√™ jogar uma moeda para cima, a probabilidade de o resultado ser cada √© de $1/2$, a probabilidade de ser coroa √© de $1/2$ e a probabilidade de ser cara ou coroa √© de $1$, porque $1/2 + 1/2 = 1$.
>
> Terceiro, se (mas somente se!) dois eventos forem independentes, ent√£o a probabilidade de esses dois eventos ocorrerem √© igual ao produto das chances individuais. Ent√£o, se voc√™ tem uma moeda n√£o viciada e lan√ß√°-la tr√™s vezes -- tenha em mente que cada lan√ßamento √© um evento independente --, a chance de o resultado dos tr√™s lan√ßamentos ser igual a coroa √© de $1/2 \times 1/2 \times 1/2 = 1/8$. (p. 154)

> A distribui√ß√£o normal [...]. Primeiro, ela √© sim√©trica em torno da sua m√©dia, de tal modo que a moda, a mediana e a m√©dia s√£o iguais. Segundo, a distribui√ß√£o normal possui √°reas abaixo da curva com dist√¢ncias espec√≠ficadas definidas a partir da m√©dia. Come√ßando da m√©dia e adicionando um desvio padr√£o para cada uma das dire√ß√µes, temos uma cobertura de 68% de toda a √°rea abaixo da curva. Adicionando mais um desvio padr√£o, passamos a ter 95% do total da √°rea. Adicionando um terceiro desviopadr√£o em cada dire√ß√£o, temos 99% da √°rea total da curva capturada.

> Imaginamos que estamos coletando uma amostra de seiscentos lan√ßamentos n√£o uma, mas um n√∫mero infinito de vezes. Podemos chamar essa hipot√©tica distribui√ß√£o das m√©dias amostrais de distribui√ß√£o amostral. Ela √© hipot√©tica, porque cientistas quase nunca podem coletar mais de uma amostra para a popula√ß√£o subjacente em um determinado ponto do tempo.
>
> Se seguirmos esse procedimento, podemos obter a m√©dia das amostras e as expor graficamente. Algumas estariam acima de 3,50, outras abaixo e algumas seriam exatamente 3,50. Por√©m, √© nesse ponto que temos o resultado-chave: a distribui√ß√£o amostral ter√° distribui√ß√£o normal, embora a distribui√ß√£o de frequ√™ncia subjacente, claramente, n√£o seja normal. 
>
> Esse √© o _insight_ do teorema do limite central. Se pud√©ssemos imaginar um n√∫mero infinito de amostras aleat√≥rias e plot√°ssemos a m√©dia de cada uma dessas amostras aleat√≥rias em um gr√°fico, essas m√©dias amostrais seriam normalmente distribu√≠das. Adicionalmente, a m√©dia da distribui√ß√£o amostral seria igual √† m√©dia da verdadeira popula√ß√£o. (p. 158-159)

> Mas sabemos que nossa amostra de seinscentos lan√ßamentos pode ser ligeiramente diferente da m√©dia verdadeira da popula√ß√£o, podendo ser tanto um pouco maior quanto um pouco menor. O que podemos fazer, portanto, √© usar nosso conhecimento de que a distribui√ß√£o amostral √© normal e invocar a regra 68-95-99 para criar um **intervalo de confian√ßa** sobre a prov√°vel localiza√ß√£o da m√©dia da popula√ß√£o.

> √â poss√≠vel que estejamos errados e que a m√©dia da popula√ß√£o esteja fora do intervalo? Sim, e ainda sabemos qu√£o prov√°vel √© que ela esteja fora do intervalo. Existem 2,5% de chance de que a m√©dia da popula√ß√£o seja menor que 3,33 e 2,5% de chance de que a m√©dia da popula√ß√£o seja maior que 3,61, em um total de 5% de chance de que a m√©dia da popula√ß√£o n√£o esteja no intervalo de 3,33 a 3,61.

O exemplo da aprova√ß√£o do Obama, explorada por uma pesquisa da NBC News e o _Wall Street Journal_ com mil americanos:

$$
\bar{Y} = \dfrac{\sum (470 \times 1) + (530 \times 0)}{1000} = 0.47
$$

$$
s_y = \sqrt{ \dfrac{470 \times (1-0.47)^2 + 530 \times (0 - 0.47)^2}{1000-1} } = 0.5
$$

Nosso melhor palpite para a m√©dia da popula√ß√£o √© $0.47$, evidentemente. Al√©m disso, o erro-padr√£o da m√©dia √© dado por:

$$
\sigma_\bar{Y} = \dfrac{0.5}{\sqrt{1000}} = 0.016
$$

Com isso podemos calcular o intervalo de confian√ßa de 95% para a m√©dia amostral:

$$
\bar{Y} \pm 2 \times \sigma_\bar{Y} = 0.47 \pm 0.032
$$

Ent√£o a taxa de aprova√ß√£o do Obama, estimada a partir dos dados do survey, fica entre 43,8% e 50,2%.

> Se estivermos interessados em estimar valores populacionais, nos baseando em nossas amostras, com a maior precis√£o poss√≠vel, ent√£o √© desej√°vel ter um intervalo de confian√ßa mais estreito do que alargado.
>
> Como podemos conseguir isso? Pela f√≥rmula do erro-padr√£o da m√©dia fica claro, utilizando √°lgebra simples, que podemos obter valores menores para o erro padr√£o de duas formas: com um numerador menor ou um denominador maior. Como obter um numerador menor -- o desvio-padr√£o da amostra -- n√£o √© algo que podemos fazer na pr√°tica, podemos considerar que √© poss√≠vel ter um denominador maior -- isto √©, aumentar o tamanho da amostra.
>
> Amostras grandes reduzir√£o o tamanho dos erros-padr√£o e amostras menores aumentar√£o o tamanho dos erros-padr√£o.

## Meireles, F., e Russo, G. (2022). Pesquisas eleitorais no Brasil: tend√™ncias e desempenho. Estudos Avan√ßados, 36, 117-131.

> Este artigo analisa as estimativas de mais de 2 mil pesquisas eleitorais com os resultados de cinco elei√ß√µes municipais e nacionais no Brasil entre 2012 e 2020. Em particular, examinamos como fatores previstos nos planos amostrais, como tamanho da amostra e modo de aplica√ß√£o de entrevistas, e outros como a dist√¢ncia temporal da data de realiza√ß√£o das pesquisas at√© o dia do pleito, predizem diferen√ßas entre estimativas e resultados oficiais. Entre outros, mostramos que pesquisas de v√©spera com amostras maiores tiveram resultados mais pr√≥ximos dos apurados nas urnas no per√≠odo, assim como pesquisas conduzidas perto do dia dos pleitos. Tamb√©m documentamos que estimativas de pesquisas em elei√ß√µes nacionais, especialmente para a Presid√™ncia e Governos estaduais em segundo turno, tendem a ser mais pr√≥ximas dos resultados do que em outras disputas. No geral, portanto, os achados indicam que as pesquisas eleitorais no Brasil t√™m desempenho similar √†s realizadas em outros contextos. (Resumo, p. 130)

> N√£o obstante a exist√™ncia de fatores relacionados aos erros em _surveys_ eleitorais, a evid√™ncia sistem√°tica de diferentes pa√≠ses mostra que pesquisas nas semanas que antecedem um pleito fornecem, em m√©dia, estimativas razoavelmente precisas do que a apura√ß√£o dos votos revelar√° -- erros t√™m, ao contr√°rio, apenas diminu√≠do ao longo dos anos (Jennings; Wlezien, 2018). Em certo sentido, dadas as dificuldades envolvidas de se desenhar planos amostrais com informa√ß√µes nem sempre atualizadas e em meio a diferentes fontes n√£o aleat√≥rias de erro, √© surpreendente o desempenho das pesquisas eleitorais ao antecipar tend√™ncias e resultados, ainda que esse n√£o seja o objetivo ou a fun√ß√£o das pesquisas (Gelman, 2021). (p. 118)

> Nossos dados revelam padr√µes importantes sobre as pesquisas eleitorais no pa√≠s. Em primeiro lugar, documentamos uma crescente no uso de abordagens telef√¥nicas no per√≠odo, bem como ligeiro aumento no tamanho das amostras utilizadas ao longo do tempo em elei√ß√µes nacionais e estaduais. Quanto aos seus resultados, as estimativas eleitorais indicam que o erro m√©dio das nossas pesquisas de v√©spera √© certa de 1.8 ponto percentual (pp), o que pode ser traduzido em uma margem de erro de 6.8 pp, maior do que o convencionalmente reportado por institutos. Isso dito, tal taxa √© compar√°vel √† de outros pa√≠ses e, mais, h√° grande varia√ß√£o entre pesquisas: as de presidentes e de governo do estado no segundo turno cometem, em m√©dia, erros menores, assim como pesquisas com maiores amostras e em pleitos com menores taxas de eleitores indecisos. (p. 119)

> Vale notar que as pesquisas eleitorais no Brasil t√™m alguns de seus aspectos regulados pela legisla√ß√£o eleitoral. Entre outros, institutos de pesquisa que queiram divulgar suas estimativas precisam fazer o registro do plano amostral a ser implementado com anteced√™ncia, reportando as datas em que a coleta dos dados ser√° feita, a data de divulga√ß√£o dos resultados, o tamanho da amostra e detalhes de metodologia como uso de quotas e discrimina√ß√£o dos locais onde entrevistas s√£o aplicadas. Em raz√£o disso, por exemplo, margens de erro divulgadas no momento do registro das pesquisas n√£o podem contemplar o efeito do uso de p√≥s-estratifica√ß√£o para corrigir desvios nas amostras, uma vez que o efeito de tais procedimentos s√≥ podem ser quantificados ap√≥s o encerramento da coleta de dados -- o que contribui para subestimar poss√≠veis erros aleat√≥rios e n√£o aleat√≥rios, isto √©, erros totais (Gramacho, 2013). (p. 121)

---

## Anota√ß√µes de aula

Em estat√≠stica, falamos sobre infer√™ncia como "realizar afirma√ß√µes sobre dados que n√£o conhecemos, a partir de dados conhecidos". No fim das contas, falar sobre uma popula√ß√£o a partir de uma amostra. Isso est√° diretamente associado ao processo gerador dos dados, i.e., o processo subjacente que est√° gerando os meus dados.

A popula√ß√£o s√£o todos os casos relevantes para a minha an√°lise. Uma amostra, ent√£o, √© um subconjunto desses casos relevantes.

A sele√ß√£o aleat√≥ria de elementos da popula√ß√£o √© a chave da amostragem probabil√≠stica:

- Aus√™ncia de vi√©s: amostragem probabil√≠stica garante que cada membro da popula√ß√£o tenha uma chance de ser inclu√≠do na amostra.
- Converg√™ncia: a variabilidade natural das amostras se equilibra √† medida que $N$ aumenta, levando a m√©dia amostral a se aproximar da verdadeira m√©dia da popula√ß√£o.

### Lei dos Grandes N√∫meros

LGN √© um princ√≠pio da teoria da probabilidade que descreve o comportamento da m√©dia de uma amostra √† medida que ela aumenta. √Ä medida que aumento a amostra, vou me aproximando da m√©dia "verdadeira", i.e., a m√©dia da popula√ß√£o.

Em uma amostra pequena, um √∫nico sorteio pode distorcer a m√©dia amostral. Em uma amostra maior, sorteios extremos se equilibram e levam a m√©dia amostram a se aproximar da m√©dia da popula√ß√£o. Para fins pr√°ticos, $N \geq 100$ reduz bastante a influ√™ncia de outliers na estimativa da m√©dia.

> Podemos pensar em 100 retiradas de 10 bolinhas, ou 1000 retiradas de 10 bolinhas. Neste caso, nossa amostra tem o mesmo tamanho, mas expandimos o n√∫mero de amostras e calculamos a m√©dia de cada uma delas. Ent√£o, a amostra tem o mesmo tamanho: $n = 10$. A m√©dia dessas m√©dias √© a m√©dia amostral.

### Teorema Central do Limite

√Ä medida que extra√≠mos mais amostras, a distribui√ß√£o da estimativa come√ßa a assumir a forma de uma distribui√ß√£o normal. 

> A distribui√ß√£o da soma (ou m√©dia) das vari√°veis aleat√≥rias independentes tende a uma distribui√ß√£o normal √† medida que o n√∫mero de amostras aumenta, independentemente da distribui√ß√£o original das vari√°veis (binomial, por exemplo).

```{r}
library(ggplot2)

# cria uma lista com 1000 amostras de 10 bolinhas, podendo elas serem azuis (1) ou vermelhas (0)
set.seed(123)
bolinhas <- replicate(1000, sample(c(0, 1), size = 10, replace = TRUE))

# isso aqui tem 1000 amostras de 10 bolinhas
bolinhas <- as.data.frame(bolinhas)

# calcula a m√©dia de cada amostra
medias <- apply(bolinhas, 2, mean)

# plota a distribui√ß√£o das m√©dias
ggplot(data.frame(medias), aes(x = medias)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = "blue", alpha = 0.5) +
  # inclui a linha da m√©dia amostral (media das medias)
  geom_vline(aes(xintercept = mean(medias)), color = "red", linetype = "dashed", size = 1) +
  stat_function(fun = dnorm, args = list(mean = mean(medias), sd = sd(medias)), color = "red") +
  labs(title = "Distribui√ß√£o das M√©dias Amostrais",
       x = "M√©dia Amostral",
       y = "Densidade")
```

Esse √© o insight do teorema central do limite. Se pud√©ssemos imaginar um n√∫mero infinito de amostras e plot√°ssemos a m√©dia de cada uma dessas amostras, essas m√©dias amostrais seriam normalmente distribu√≠das. Adicionalmente, a m√©dia da distribui√ß√£o amostral seria igual √† m√©dia da verdadeira popula√ß√£o.

De fato, outra propriedade interessante √© a dispers√£o da m√©dia amostral. A m√©dia amostral tende a ser menos dispersa do que a m√©dia populacional. Isso √© chamado de erro padr√£o da m√©dia (EPM). O EPM √© a medida da variabilidade das m√©dias amostrais em torno da m√©dia populacional.
O EPM √© calculado como o desvio padr√£o da popula√ß√£o dividido pela raiz quadrada do tamanho da amostra:

$$
EPM = \dfrac{\sigma}{\sqrt{n}}
$$

onde $\sigma$ √© o desvio padr√£o da popula√ß√£o e $n$ √© o tamanho da amostra.
O EPM diminui √† medida que o tamanho da amostra aumenta. Isso significa que, quanto maior a amostra, mais precisa ser√° a estimativa da m√©dia populacional. Isso √© importante porque nos permite fazer infer√™ncias sobre a popula√ß√£o com base em uma amostra.

### Intervalo de Confian√ßa
Um intervalo de confian√ßa √© uma faixa de valores que, com um certo n√≠vel de confian√ßa, cont√©m o valor verdadeiro de um par√¢metro populacional. O intervalo de confian√ßa √© calculado a partir da m√©dia amostral e do erro padr√£o da m√©dia.

O intervalo de confian√ßa √© calculado como:
$$
IC = \bar{X} \pm Z_{\alpha/2} \cdot EPM
$$

onde $\bar{X}$ √© a m√©dia amostral, $Z_{\alpha/2}$ √© o valor cr√≠tico da distribui√ß√£o normal padr√£o correspondente ao n√≠vel de confian√ßa desejado (por exemplo, 1,96 para um intervalo de confian√ßa de 95%) e $EPM$ √© o erro padr√£o da m√©dia.

O intervalo de confian√ßa fornece uma estimativa da incerteza associada √† m√©dia amostral. Se o intervalo de confian√ßa for estreito, isso indica que a m√©dia amostral √© uma boa estimativa da m√©dia populacional. Se o intervalo de confian√ßa for amplo, isso indica que a m√©dia amostral √© uma estimativa menos precisa da m√©dia populacional.

> O valor de 1.96 √© o valor cr√≠tico da distribui√ß√£o normal padr√£o que corresponde a um n√≠vel de confian√ßa de 95%. Isso significa que, se repetirmos o processo de amostragem muitas vezes, aproximadamente 95% dos intervalos de confian√ßa calculados conter√£o a m√©dia populacional verdadeira. Al√©m disso, o intervalo de 95% √© arbitr√°rio: por exemplo, 68% de confian√ßa corresponde a 1 desvio padr√£o, 99% de confian√ßa corresponde a 2.58 desvios padr√£o, e assim por diante.

Vamos supor o caso em que queremos estimar a aprova√ß√£o do Lula. Pegamos 1000 amostras e estimamos uma m√©dia de aprova√ß√£o de 32%. O desvio padr√£o, portanto, ser√° calculado como:

$$
s = \sqrt{ 0.32 \cdot (1 - 0.32) } = 0.47,
$$

e o erro padr√£o da m√©dia ser√°:
$$
\text{EPM} = \dfrac{0.47}{\sqrt{1000}} = 0.015
$$

O intervalo de confian√ßa de 95% para a m√©dia amostral √© dado por:
$$
\text{IC} = 0.32 \pm 1.96 \cdot 0.015
$$

Ou seja, o intervalo de confian√ßa √© dado por:
$$
\text{IC} = (0.32 - 0.03, 0.32 + 0.03) = (0.29, 0.35)
$$

---

### A vari√¢ncia da Bernoulli

üí°Dedico essa parte das anota√ß√µes a provar o motivo de a vari√¢ncia da Bernoulli poder ser escrita como $p(1-p)$, sendo $p$ a propor√ß√£o de $X = 1$ em um conjunto.

Quando estamos tratando de uma vari√°vel aleat√≥ria $X$ que segue uma distribui√ß√£o Bernoulli, sabemos que os valores de $X$ s√≥ assumem valores em $\{0, 1\}$. Al√©m disso, sabemos que $\mathbb{E}[X] = p$. A f√≥rmula da vari√¢ncia √©:

$$
\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2
$$

No entanto, sabemos que, como as observa√ß√µes de $X$ s√≥ assume valores em $\{0, 1\}$, vale que $\mathbb{E}[X^2] = \mathbb{E}[X] = p$ e que $(\mathbb{E}[X])^2 = p^2$. Com efeito:

$$
\begin{align*}
\text{Var}(X) &= \mathbb{E}[X^2] - (\mathbb{E}[X])^2 \\
              &= p - p^2 \\
              &= p(1 - p)
\end{align*}
$$

Apenas para fixar, vamos provar tamb√©m o porqu√™ de podermos escrever a vari√¢ncia como $\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2$.

A vari√¢ncia, por defini√ß√£o, √© a diferen√ßa quadr√°tica entre a m√©dia de uma vari√°vel e o valor observado. Isto √©:

$$
\text{Var}(X) = \mathbb{E}[(X - \mathbb{E}[X])^2]
$$

Podemos expandir essa express√£o e manipul√°-la usando a propriedade da linearidade da esperan√ßa:

$$
\begin{align*}
\text{Var}(X) &= \mathbb{E}[(X - \mathbb{E}[X])^2] \\
              &= \mathbb{E}[X^2 - 2X\mathbb{E}[X] + (\mathbb{E}[X])^2] \\ 
              &= \mathbb{E}[X^2] - 2\mathbb{E}[X]\mathbb{E}[X] + (\mathbb{E}[X])^2 \\ % pela linearidade
              &= \mathbb{E}[X^2] - 2(\mathbb{E}[X])^2 + (\mathbb{E}[X])^2 \\
              &= \mathbb{E}[X^2] - (\mathbb{E}[X])^2 \\
\end{align*}
$$
